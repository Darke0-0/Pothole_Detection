{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "from model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation instances: 4336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4336 [00:00<?, ?it/s]C:\\Users\\Darke\\AppData\\Local\\Temp/ipykernel_20112/2044359032.py:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image = np.transpose(image, (2, 0, 1)).astype(np.float)\n",
      "D:\\Python\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 4336/4336 [54:07<00:00,  1.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST PREDICTIONS COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set the computation device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# load the model and the trained weights\n",
    "model = model().to(device)\n",
    "model.load_state_dict(torch.load('Data/checkpoints/fasterrcnn_resnet50_fpn.pth'))\n",
    "\n",
    "DIR_TEST = 'Test'\n",
    "test_images = os.listdir(DIR_TEST)\n",
    "print(f\"Validation instances: {len(test_images)}\")\n",
    "\n",
    "detection_threshold = config.PREDICTION_THRES\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, image in tqdm(enumerate(test_images), total=len(test_images)):\n",
    "        orig_image = cv2.imread(f\"{DIR_TEST}/{test_images[i]}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        # make the pixel range between 0 and 1\n",
    "        image /= 255.0\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float)\n",
    "        image = torch.tensor(image, dtype=torch.float).cuda()\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "        outputs = model(image)\n",
    "        \n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        if len(outputs[0]['boxes']) != 0:\n",
    "            for counter in range(len(outputs[0]['boxes'])):\n",
    "                boxes = outputs[0]['boxes'].data.numpy()\n",
    "                scores = outputs[0]['scores'].data.numpy()\n",
    "                boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "                draw_boxes = boxes.copy()\n",
    "                \n",
    "            for box in draw_boxes:\n",
    "                cv2.rectangle(orig_image,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            (0, 0, 255), 3)\n",
    "                cv2.putText(orig_image, 'PotHole', \n",
    "                            (int(box[0]), int(box[1]-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), \n",
    "                            2, lineType=cv2.LINE_AA)\n",
    "            cv2.imwrite(f\"test_predictions/{test_images[i]}\", orig_image,)\n",
    "print('TEST PREDICTIONS COMPLETE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "def convert_frames_to_video(pathIn,pathOut,fps):\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    # print(files)\n",
    "    #for sorting the file names properly\n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predictions/G0011476.JPG\n",
      "test_predictions/G0011523.JPG\n",
      "test_predictions/G0011524.JPG\n",
      "test_predictions/G0011562.JPG\n",
      "test_predictions/G0011585.JPG\n",
      "test_predictions/G0011587.JPG\n",
      "test_predictions/G0011601.JPG\n",
      "test_predictions/G0011602.JPG\n",
      "test_predictions/G0011603.JPG\n",
      "test_predictions/G0011614.JPG\n",
      "test_predictions/G0011616.JPG\n",
      "test_predictions/G0011661.JPG\n",
      "test_predictions/G0011662.JPG\n",
      "test_predictions/G0011664.JPG\n",
      "test_predictions/G0011677.JPG\n",
      "test_predictions/G0011678.JPG\n",
      "test_predictions/G0011705.JPG\n",
      "test_predictions/G0011769.JPG\n",
      "test_predictions/G0011772.JPG\n",
      "test_predictions/G0011773.JPG\n",
      "test_predictions/G0011876.JPG\n",
      "test_predictions/G0011878.JPG\n",
      "test_predictions/G0011881.JPG\n",
      "test_predictions/G0011966.JPG\n",
      "test_predictions/G0011969.JPG\n",
      "test_predictions/G0011970.JPG\n",
      "test_predictions/G0011978.JPG\n",
      "test_predictions/G0011981.JPG\n",
      "test_predictions/G0011982.JPG\n",
      "test_predictions/G0011986.JPG\n",
      "test_predictions/G0011988.JPG\n",
      "test_predictions/G0011989.JPG\n",
      "test_predictions/G0012011.JPG\n",
      "test_predictions/G0012012.JPG\n",
      "test_predictions/G0012022.JPG\n",
      "test_predictions/G0012023.JPG\n",
      "test_predictions/G0016156.JPG\n",
      "test_predictions/G0016157.JPG\n",
      "test_predictions/G0016237.JPG\n",
      "test_predictions/G0016238.JPG\n",
      "test_predictions/G0016241.JPG\n",
      "test_predictions/G0016242.JPG\n",
      "test_predictions/G0016243.JPG\n",
      "test_predictions/G0016244.JPG\n",
      "test_predictions/G0016245.JPG\n",
      "test_predictions/G0016329.JPG\n",
      "test_predictions/G0016330.JPG\n",
      "test_predictions/G0016433.JPG\n",
      "test_predictions/G0016499.JPG\n",
      "test_predictions/G0016500.JPG\n",
      "test_predictions/G0016516.JPG\n",
      "test_predictions/G0016517.JPG\n",
      "test_predictions/G0016561.JPG\n",
      "test_predictions/G0016563.JPG\n",
      "test_predictions/G0016608.JPG\n",
      "test_predictions/G0024296.JPG\n",
      "test_predictions/G0024745.JPG\n",
      "test_predictions/G0024746.JPG\n",
      "test_predictions/G0024747.JPG\n",
      "test_predictions/G0024750.JPG\n",
      "test_predictions/G0024751.JPG\n",
      "test_predictions/G0025405.JPG\n",
      "test_predictions/G0025406.JPG\n",
      "test_predictions/G0025407.JPG\n",
      "test_predictions/G0025408.JPG\n",
      "test_predictions/G0025822.JPG\n",
      "test_predictions/G0026516.JPG\n",
      "test_predictions/G0026519.JPG\n",
      "test_predictions/G0026520.JPG\n",
      "test_predictions/G0026521.JPG\n",
      "test_predictions/G0026801.JPG\n",
      "test_predictions/G0027032.JPG\n",
      "test_predictions/G0027190.JPG\n",
      "test_predictions/G0027191.JPG\n",
      "test_predictions/G0027228.JPG\n",
      "test_predictions/G0027229.JPG\n",
      "test_predictions/G0027230.JPG\n",
      "test_predictions/G0027231.JPG\n",
      "test_predictions/G0027232.JPG\n",
      "test_predictions/G0027233.JPG\n",
      "test_predictions/G0027317.JPG\n",
      "test_predictions/G0027504.JPG\n",
      "test_predictions/G0027505.JPG\n",
      "test_predictions/G0027516.JPG\n",
      "test_predictions/G0027694.JPG\n",
      "test_predictions/G0027695.JPG\n",
      "test_predictions/G0027801.JPG\n",
      "test_predictions/G0027848.JPG\n",
      "test_predictions/G0027851.JPG\n",
      "test_predictions/G0027852.JPG\n",
      "test_predictions/G0027856.JPG\n",
      "test_predictions/G0027857.JPG\n",
      "test_predictions/G0027897.JPG\n",
      "test_predictions/G0027958.JPG\n",
      "test_predictions/G0027975.JPG\n",
      "test_predictions/G0028158.JPG\n",
      "test_predictions/G0028193.JPG\n",
      "test_predictions/G0028194.JPG\n",
      "test_predictions/G0028195.JPG\n",
      "test_predictions/G0028196.JPG\n"
     ]
    }
   ],
   "source": [
    "pathIn= 'test_predictions/'\n",
    "pathOut = 'video.avi'\n",
    "fps = 25.0\n",
    "convert_frames_to_video(pathIn,pathOut,fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
